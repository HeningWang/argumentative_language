\documentclass[10pt,letterpaper]{article}

\usepackage{cogsci}
\usepackage{CSPstyles}
\usepackage{comment}

% \cogscifinalcopy %%% Uncomment this line for the final submission

%%% Bibliography %%%
\usepackage[
  style=apa,
  natbib=true,
  annotation=false,
  sortcites=false,
]{biblatex}
\addbibresource{../paper/RSArg.bib} %%% Specify the path to a BibLaTeX file
\setlength{\bibhang}{.125in}

\usepackage{float} %%% Roger Levy added this and changed figure/table placement to [H] for conformity to Word template, though floating tables and figures to top is still generally recommended!

% Sometimes it can be useful to turn off hyphenation for purposes such as spell checking of the resulting PDF.
% \usepackage[none]{hyphenat} %%% Uncomment to turn off hyphenation

%========================================
% Packages
%========================================

% \usepackage{amsmath}
% \usepackage{amsfonts}           % Fonts for Formulas
% \usepackage{amssymb}
% \usepackage{amsthm}
% \usepackage{dsfont}             % double stroke fonts
\usepackage[final]{graphicx}
\usepackage{booktabs}
\usepackage{enumerate}
\usepackage{paralist}

% \usepackage[all]{xy}
\usepackage{url}

\usepackage{gb4e}
\noautomath
\renewcommand{\eachwordtwo}{\relsize{-1}} % format translation in glosses
% \renewcommand{\trans}{\vskip.15\baselineskip\relsize{-1}}
\renewcommand{\trans}{\vskip.15\baselineskip}

\usepackage{lipsum}
% \usepackage{txfonts} % for strict implication symbols
\usepackage{soul}
\usepackage{relsize} % command \relsize{+/-x} for relative font size
% \usepackage[ngerman,english]{babel}
% \usepackage[utf8]{inputenc}
% \usepackage[T1]{fontenc}
\usepackage{xypic}
\usepackage{setspace}
\usepackage{xspace} % for \xspace in definition of acronyms etc.

\DeclareMathOperator{\expo}{exp}
\newcommand{\den}[1]{\ensuremath{[\![#1]\!]}}
\newcommand{\interpret}[1]{\ensuremath{\den{#1}}}

\newcommand{\hw}[1]{\textcolor{glaucous-bright}{[HW: #1]}}
\newcommand{\mf}[1]{\textcolor{shimmer-main}{[MF: #1]}}
\newcommand{\fc}[1]{\textcolor{opal-bright}{[FC: #1]}}
\DefineNamedColor{named}{mycol2}{cmyk}{0.8,0,0.8,0.2}
\newcommand{\mycolh}[1]{{\textcolor{mycol2}{#1}}}
\newcommand{\mymark}[1]{{\color{mycol}{#1}}}

% margin lines for drafty passages
\usepackage{mdframed}
\newmdenv[
  topline=false,
  bottomline=false,
  rightline=false,
  linecolor=gray,
  linewidth=1pt,
  skipabove=\topsep,
  skipbelow=\topsep
]{draftytext}


\title{What guides speakers' utterance choice in argumentative language use?}

%%% Format authors using helper functions from authblk package %%%
\author[1]{\mbox{Author N. One (a1@uni.edu)}}
\author[2]{\mbox{Author Number Two}}
\affil[1]{Department of Hypothetical Sciences, University of Illustrations}
\affil[2]{Department of Example Studies, University of Demonstrations}

%%% Or, format authors manually %%%
% \author{
%   {\large\bfseries Author N. One (a1@uni.edu)$^1$ \& Author Number Two$^2$} \\
%   {\normalsize\normalfont
%     $^1$Department of Hypothetical Sciences, University of Illustrations \\
%     $^2$Department of Example Studies, University of Demonstrations
%   }
% }

\begin{document}


\maketitle


\noindent
\hspace*{0.2\linewidth}%
\parbox{0.8\linewidth}{%
  \itshape
  \footnotesize
  ``Today in Timiryazevsky Park [two] world leaders participated in a 100 meter foot race.
      Our Soviet Premier, Nikita Khrushchev, finished a very respectable second place.
      The poor American President, John F.~Kennedy finished a miserable next-to-last.'' \\
      \hfill --- \textcolor{gray}{ascribed to Russian newspaper \textit{Pravda}}
}

\bigskip


  % \begin{footnotesize}
  %   \begin{quote}
  %     \noindent
  %     % \textbf{A Foot Race In Moscow Between World Leaders.}
  %     Today in Timiryazevsky Park [two] world leaders participated in a 100 meter foot race.
  %     Our Soviet Premier, Nikita Khrushchev, finished a very respectable second place.
  %     The poor American President, John F.~Kennedy finished a miserable next-to-last. \\
  %     \hfill (\textcolor{gray}{[ascribed to newspaper \textit{Pravda}\footnote{Taken from: \url{https://www.linkedin.com/pulse/foot-race-between-john-f-kennedy-nikita-khrushchev-tom-salamone}}]})
  %   \end{quote}
  % \end{footnotesize}



\begin{abstract}
  Concrete. \mf{fill me \dots}

\textbf{Keywords:}
pragmatic language use;
argumentative framing;
argument strength;
probabilistic modeling;
\end{abstract}

\section{Introduction}
\label{sec:introduction}

Overwhelming evidence from decades of research demonstrates that human language use is often strongly oriented towards providing a high degree of useful information for addressees \citep{Grice1975:Logic-and-Conve}.
% This picture aligns well with the classic Gricean framework \citep{Grice1975:Logic-and-Conve}, which posits a cooperative principle alongside Maxims of Quality (truth), Quantity (informativity), and Relevance---where the latter is typically interpreted as relevance to the listener.
Formal models of pragmatic language use consequently often rely on formal notions of informativity ---such as supplied by formal logic or information theory--- to describe speakers' pragmatic choice of expressions as a form of utility maximization, defined---at least in part---by the drive to optimize relevant information exchange \citep[e.g.,][]{Parikh1991:Communication-a,BlutnerBOTJoS2000,FrankGoodman2012:Predicting-Prag}.
Yet, some authors argue that the purpose of communication may be much more about persuasion, argumentation, manipulation, and opinion-negotiation than about pure, objective---indeed, robot-like---information-sharing \citep[e.g.,][]{AnscombreDucrot1983:Largumentation-,MercierSperber2011:Why-do-humans-r,Enfield2024:Language-vs.Rea}.
To give an example of selective truth-telling, or \emph{paltering} \citep{RogersZeckhauser2017:Artful-palterin}, the outcome of an exam could be truthfully described with roughly similar information value with different expressions, framing the exam as easy (\ref{bsp:leading-example-easy}) or difficult (\ref{bsp:leading-example-difficult}).

\begin{exe}
  \item \label{bsp:leading-example}
  \begin{xlist}
    \item
    \label{bsp:leading-example-easy}
    Most of the students got most questions right.
    \item
    \label{bsp:leading-example-difficult}
    Some of the students got all questions wrong.
  \end{xlist}
\end{exe}

While formal notions of informativity are ready at hand, what is lacking are good formal descriptions of what makes one utterance more suitable than another for a speaker with an intent to argumentatively frame their contribution, as in the above example.
In this work, we therefore ask which kind of utility function might underlie a speaker's choice to prefer one utterance over another in a persuasive or argumentative context: how can we capture formally what makes one argument better than another?
We address this question through the notion of \emph{argumentative strength}.

Some prior work \citep[e.g.,][]{Merin1997:If-all-our-argu,Rooijvan-Rooij2004:Cooperative-ver,Winterstein2012:What-but-senten} suggests a formalization of argumentative strength in terms of \textit{log-likelihood ratios}, based on early work on observational evidence \citep{Good1950:Probability-and}; see the formalization below.
However, so far there has been no stringent empirical testing of this notion, nor a systematic comparison against alternative formalization in terms of their predictive accuracy for experimental data.
Providing such a comparison is the main contribution of this work.

We focus on a setting of selective truth-telling, or paltering \citep{RogersZeckhauser2017:Artful-palterin}.
We study cases like (\ref{bsp:leading-example}), which are similar to the real-life examples examined by \citet{CumminsFranke2021:Rational-interp}, but consider a constrained experimental setting that allows statistical model comparison of bespoke probabilistic models which differ only in the quantitative notion of argumentative strength they assume underlies the speakers' choice of expression.
In the following, we formulate these models in the tradition of the RSA framework \citep{FrankGoodman2012:Predicting-Prag,FrankeJager2015:Probabilistic-p,Degen2023:The-Rational-Sp}.
We then describe the experimental set-up, and report on the statistical model comparisons, as well as our results.
Our main findings are that \mf{fill me \dots}.


\section{Probabilistic models of argumentative language}
\label{sec:prob-pragm}

Probabilistic models of pragmatic reasoning usually define a speaker and listener policy.
Here, we will focus exclusively on the speaker's policy.
In line with the usual assumption of Bayesian decision-makers, the speaker's policy of choosing an utterance $u$, when trying to communicate a state $s$ is defined in terms of a soft-max operation \citep{FrankeDegen2023:The-softmax-fun}, with parameter $\alpha$ on the utility function $U(u,s)$:
\begin{align}
  \label{eq:S1}
  P_{S} (u \mid s) & \propto \expo\left( \alpha U( u , s ) \right)\,.
\end{align}
The utility function $U(u,s)$ captures how good it is for the speaker to choose $u$ when the true state, according to the speaker, is $s$.
We here follow the Rational Speech Act (RSA) modeling framework \citep[e.g.,][]{FrankGoodman2012:Predicting-Prag,FrankeJager2015:Probabilistic-p,Degen2023:The-Rational-Sp} which adopts the usual Gricean assumptions that the speaker wants to speak truly, maximize the amount of information conveyed about the state $s$, and to minimize their own speaking effort \citep{Grice1975:Logic-and-Conve}.
To implement these assumptions, utilities are defined as a sum of the information-theoretic surprisal of $s$ conditional on $u$ being true and the (negative) cost of $u$, which is a stand-in for production effort or ease of accessibility:
\begin{align}
  \label{eq:util-vanilla}
  U(u , s) &= \log P(s \mid \interpret{u}) - \text{cost}(u)\,,
\end{align}
where $\interpret{u} \subseteq S$ is the semantic denotation of $u$, formally represented as the set of world states in which $u$ is true.
Under the wide-spread assumption of a flat prior over $s$, the conditional probability of $s$ given that $u$ is true can be written as:
\begin{align*}
P(s \mid \interpret{u})
    &=
    \begin{cases}
        |\interpret{u}|^{-1} & \text{if } s \in \interpret{u} \\
        0 & \text{otherwise.}
    \end{cases}
\end{align*}
For a binary semantics (as assumed here), the utility function factors into three well-known aspects of pragmatic language generation, namely that the utterance be true, informative and economical \citep{ScontrasTessler2021:A-practical-int}:
\begin{align*}
  U(u , s) &=
             \underbrace{\log \left[ s \in \interpret{u} \right]}_{\text{truth}}
             \ + \
             \underbrace{\log \interpret{u}^{{-1}}}_{\text{informativity}}
             \ - \
             \underbrace{\text{cost}(u)}_{\text{economy}} \,.
\end{align*}

The speaker's policy defined above in Equation~\eqref{eq:S1}, when used with the standard utility function in Equation~\eqref{eq:util-vanilla} has been productively used to explain choices of utterances for different linguistic constructions of phenomena, e.g., for referential expressions \citep{FrankGoodman2012:Predicting-Prag}, generics \citep{Tessler2019:The-Language-of}, conditionals \citep{GrusdtLassiter2021:Probabilistic-m}, quantifiers and implicature \citep{GoodmanStuhlmuller2013:Knowledge-and-I,Tielvan-TielFranke2021:Probabilistic-p}, gradable adjectives \citep{LassiterGoodman2015:Adjectival-vagu}, or probability expression \citep{HerbstrittFranke2019:Complex-probabi}.
Yet, some phenomena seem to require more elaborate utility functions.
For example, models have been explored which incorporate additional utility components related to politeness \citep{YoonTessler2020:Polite-Speech-E} or opinion \citep{AchimovaFranke2025:The-alignment-m}.
Here, we take a similar approach to modelling the utility trade-off between truth and informatively, on the one hand, and, on the other, making an argument in favor of a position or hypothesis $H_{0}$, as opposed to the competing position or hypothesis $H_{1}$.
The form of the utility functions we consider here is:
\begin{align}
  & U(u , s , H_{0} , H_{1}) =  \label{eq:utilArgstrength} \\  \nonumber
  & \underbrace{{\mycolh{\beta}} \ \log P_{L_0} (s \mid \interpret{u})}_{\text{truth \& informativity}}
 \  + \
      \underbrace{(\mycolh{1-\beta}) \ \text{argstr}(u, H_{0} , H_{1})}_{\text{argumentative strength}}
 \ - \
    \underbrace{\text{cost}(u)}_{\text{economy}}
\end{align}
Following the previous literature, the parameter $\beta$ models the degree to which a speaker values optimizing informativity of an utterance or making a strong argument for position $H_{0}$ (relative to $H_{1}$).
% For the special case of $\beta = 1$, this formulation reduces to the previous utility function which did not have argumentative strength as an additional speaker objective for utterance selection.

In the following we will explore different models of the speaker's utterance choice:
\begin{enumerate}
  \item The \textbf{vanilla RSA model} provides the conservative baseline. It contains no speaker objective for argumentative speech; alternatively we can think of it as a model with $\beta=1$.
  \item The \textbf{likelihood-ratio model} assumes that argumentative strength can be operationalized in analogy to a common measure of observational evidence, the log-likelihood ratio (based on literal interpretation of the utterance).
  \item The \textbf{pragmatic likelihood-ratio model} is similar to the previous model but computes argumentative strength via log-likelihood ratios based on a pragmatic enrichment of the utterance.
  \item  The \textbf{maximin model} provides a computationally simpler definition of argumentative strength in terms of a form of worst-case reasoning.
  \item The \textbf{model-free model} uses a situation-specific notion of argumentative strength in terms of the posterior expectation of true answers; this approach is ``model-free'' in the sense that it does not commit to a strong theoretic position on what argument strength is supposed to be.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiment}
\label{sec:experiment-1}

To test whether and how speakers choose expressions for purposes of argumentative framing, we used an experimental design which presents a perspicuous but complex state of affairs (the results of a high-school exam) and allows participants to choose flexibly from a larger, but still constrained set of alternative expressions.
The design used here is essentially the same as that of Experiment~1 reported in \citep{Vinicius-Macuch-SilvaWinter2024:Strategic-use-o}, except that we here used a larger set of visual scenes (different array sizes, see below).
While the work reported by \citet{Vinicius-Macuch-SilvaWinter2024:Strategic-use-o} also elicited and analyzed free production data, we here focus on a more constrained free-choice task in order to harness the complexity of the data for subsequent modeling.
Participants could essentially choose one of 32 sentences, but they did so by individual selection of (i) an outer quantifier, (ii) an inner quantifier, and (iii) an adjective, to complete the sentence frame in (\ref{bsp:sentences-Exp}), where OQ and IQ $\in \{$ None, Some, Most, All $\}$, and ADJ $\in \{$ right, wrong $\}$.

\begin{exe}
  \ex \label{bsp:sentences-Exp}
  OQ of the students got IQ of the questions ADJ
\end{exe}

\paragraph{Participants.}
A total of $N=201$ adult participants with English as their first language were recruited via Prolific and were paid £1.5 (hourly wage approximately £9).
% (self-identified gender: 88 female, 111 male, 1 other and 1 non-disclosed; mean age (of those who revealed it) 30.3 (standard deviation 8.07), min 18 and max 60).
% Participants had to be at least 18 years old in order to participate.
% Based on a mean completion time of just below 10 minutes (median just below 9 minutes), this amounted to an average hourly payment of £1.5.

\paragraph{Materials.}
The results of high-school exams were presented visually in form of matrices.
\mf{if there's space: insert a picture of a stimulus}
The rows of matrices corresponded to students (indicated by names), the columns indicated questions.
A checkmark on green background in a cell represented that the student got the question right.
A cross on a red background represented a false answer.
The results where always arranged to show students ordered in terms of performance (students with more correct answers on in higher rows).
The names of students were sampled at random for each trial from a list of common English first names.

Four sizes of matrices were used, differing in the number of students (5 or 11) and the number of questions in the exam (6 and 12).
% For example, the matrix in Figure~\ref{fig:overview} is an instance of a $5 \times 12$ matrix.
For each matrix size, there were 20 instances, each one corresponding to one of the 20 situations which can be logically distinguished based on sentences of the form in (\ref{bsp:sentences-Exp}).\footnote{
  More concretely, the 20 situations are all the ``possible world states'' that can be differentiated with a language that contains only the sentences in (\ref{bsp:sentences-Exp}) under their standard logical meaning, assuming that \textit{some} means \textit{at least one} and \textit{most} means \textit{more than half} \citep[see][for details]{Vinicius-Macuch-SilvaWinter2024:Strategic-use-o}.
}

\paragraph{Procedure.}
The experiment started with an explanation of the displays and the task.
As a within-subjects manipulation (high vs.~low framing condition), participants were asked to truthfully describe the exam results as either favorable or unfavorable (students did well/poorly, exam was easy/hard).
Each participant saw each of the 20 instances of the same matrix size in completely randomized order.
Each participant saw 10 trials in the high and low framing condition each, randomly assigned for each run.

\paragraph{Results.}
Following preregistered protocol, \mf{insert anonymous link?} we excluded all the data from a participant if the participant selected the same response in all trials or if the participant gave more than four responses which are literally false as a description of the results shown in the corresponding trial.
This reduced the original number of $N=201$ participants to $N=186$.
We also excluded any remaining responses that are literally false.
This resulted in another $113$ individual responses being removed from the data set.

Figure~\ref{fig:results-exp1} shows the proportions of sentences which participants generated as descriptions for the exam results.
The plot differentiates the two framing conditions (\textit{high} vs.~\textit{low}, indicated by color), and the four different shapes of the matrices that represented the exam results (different rows in the figure).
% Visually, the distributions for different matrix sizes seem to be rather similar, but there appear to be striking contrasts in the choices of descriptions between the two different argumentative framing conditions.
% This impression is corroborated by a simple $\chi^{2}$-test.
The choice distributions seem to differ slightly between results matrices ($\chi^{2} \approx 216.8$, $\text{df}=168$, $p < 0.006$).
More importantly, the \textit{high} vs.~\textit{low} framing induced significantly different distributions over descriptions ($\chi^{2} \approx 2300.7$, $\text{df}=103$, $p < 2e^{-16}$).
The latter result suggests that our manipulation worked and that participants are indeed able to adapt their description choices to the strategic argumentative framing the context demanded.


\begin{figure*}[t]
  \centering
  \includegraphics[width=1.0\textwidth]{../data/pics/barplot_responses_perConditions.pdf}
  \caption{
    Proportion of sentences generated in Experiment~1.
    The bars show the observed proportions of sentences generated by the participants using the template in (\Ref{bsp:sentences-Exp}).
    Each row shows the results for a different matrix size.
  }
  \label{fig:results-exp1}
\end{figure*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Statistical Analysis}
\label{sec:models}

We perform a Bayesian analysis of the data produced by the experiment, using the RSA speaker defined in Eq.~\ref{eq:S1} as a generative model of participants' production behaviour. A full implementation of argumentative strength (Eq.~\ref{eq:utilArgstrength}) requires the specification of one hypothesis that the speaker argues for ($H_0$) and one that they argue against ($H_1$), as well as a functional form that measures how strongly a specific utterance supports $H_0$ against $H_1$.

\subsection{Hypotheses for argstrength calculation}

We model each hypothesis $H$ as saying that all students in the class have a certain probability $\gamma_H$ of getting each answer correct, making the simplifying assumption that there is no variation in skill across students and no variation in probability of getting different answers correct. 
\fc{I actually spent a long time in the early phases of the project exploring variations of this - not sure it makes sense to pick up this thread though.}
The probability of observing 	the results for a class is then proportional to the product of the Binomial probability of each student's results:
  %
  \begin{equation}\label{eq:stateprob}
    P(s \mid \gamma_H) \propto \prod_{k \in s}{ N \choose k } \gamma_H^k (1-\gamma_H)^{N-k}
  \end{equation}
  %
where the exam $s$ is encoded as a list of numbers of correct answers for each student, and $N$ is the number of questions in the exam.

For the models below, the hypotheses are:
 \begin{align}\label{eq:hypotheses}
\gamma_{H_0} &= 0.85 &\gamma_{H_1} &= 0.15 & \text{for high frame condition.} \\
\gamma_{H_0} &= 0.15 &\gamma_{H_1} &= 0.85 & \text{for low frame condition.}\nonumber
 \end{align}
Intuitively, in the high framing condition the speaker is choosing an utterance to support the hypothesis that students had a high probability of answering correctly rather than a low probability, and the opposite is true in the low framing condition. 

\subsection{Functional form of the argstrength component}

Having defined the two hypotheses, we next turn to various ways of specifying the functional form of the argumentative strength of utterances.

\paragraph{Log likelihood ratio argstrength.} The starting point is the notion of \emph{weight of evidence}, which has been introduced in the previous literature as a formal notion of argument strength, following \mf{refs}.
%This notion requires fixing two competing hypotheses $H_{0}$ and $H_{1}$ and formalizes the argumentative strength of an utterance $u$ as evidence in favor of $H_{0}$ as opposed to the (alternative, competing) hypothesis $H_{1}$.
Concretely, we consider the degree to which the utterance $u$ is more likely to be true (literally) under hypothesis $H_{0}$ than under a competing (alternative) hypothesis $H_{1}$:
%
\begin{equation}
    \text{lr-argstr}(u, H_0, H_1) = 
    \log \frac{P( \interpret{u} \mid H_0 ) }{ P( \interpret{u} \mid H_1 ) }
\end{equation}
%
\noindent where $P( \interpret{u} \mid H )$ is the probability that utterance $u$ is \emph{true} (rather than e.g., produced) given hypothesis $H$. $P(\interpret{u} \mid H)$ can be calculated based on the literal semantics:
\begin{equation}
    P(\interpret{u} \mid H) = \sum_{s \in S} \interpret{u}^s P(s \mid \gamma_H)
\end{equation}
where $P(s \mid \gamma_H)$ is defined in Eq.~\eqref{eq:stateprob}, and $\interpret{u}^s$ equals 1 if $u$ is true in $s$ and 0 otherwise.

\paragraph{Pragmatic argstrength.} The second type of argstrength replaces truth in a state $ \interpret{u}^s$ with the probability of production by a pragmatic speaker:
\begin{equation}
\textrm{prag-argstr}(u, H_0, H_1) = \log \frac{P_{S} (u \mid H_0)}{P_{S} (u \mid H_1)}
\end{equation}
\noindent where:
\begin{equation}
P_{S} (u \mid H) = \sum_{s \in S} P_{S} (u \mid s) P(s \mid \gamma_H)
\end{equation}
and $P_{S}$ is the pragmatic speaker defined above in Equations~\eqref{eq:S1} and~\eqref{eq:util-vanilla}, who does not in turn consider argumentative strength. \fc{add a sentence or two giving an intuition/motivation for prag-argstr.}

\paragraph{Maximin argstrength.} The third type of argstrength captures the intuition that, rather than calculating argumentative strength by marginalizing across \emph{all} the states compatible with the utterance $u$, participants only consider the argumentatively weakest state compatible with $u$:
  \begin{equation}
    \text{maximin-argstr}(u, H_0, H_1) =
      \min_{s \in \interpret{u}} \log \frac{p( s \mid \gamma_{H_0})}{p( s \mid \gamma_{H_1})} 
  \end{equation}
A speaker might use maximin-argstr when considering the worst case scenario for a listener who guesses a single one of the states compatible with the utterance. 
% For instance, for utterance `all|some|right' in the experiment, this would be state $[3,3,3,3,3]$ in the high framing and $[12,12,12,12,12]$ in the low framing. 
Maximin-argstr can also be motivated on computational grounds, since it only requires the single argumentatively weakest state, which in some cases can be found efficiently. 
%Maximin- and lr-argstrength differ in terms of the absolute argstrength of signals, and in some cases also in their ranks. For instance, in the high framing condition `most|none|wrong' is better than `all|most|right' for lr-argstr, but the other way around for maximin-argstr.

\paragraph{Model-free argstrength.} Instead of assessing argstrength in terms of a precise probabilistic relation between hypotheses and utterance-compatible observations, participants might use a heuristic higher-level feature of observations. One such feature for our experimental setup is the mean number of right answers across utterance-compatible observations:
\begin{equation}
    \mathbb{E}_{\text{right}}(u) = |\interpret{u}|^{-1} \sum_{s \in \interpret{u}} \sum_{i \in s} i 
 \end{equation}
The argumentative speaker might choose an utterance to maximise this (centered) quantity in the high frame condition, and to minimize it in the low frame condition:
\begin{equation}
\text{mf-argstrength}(u) = 
\begin{cases}
    \mathbb{E}_{\text{right}}(u) - \mu_{\mathbb{E}_{\text{right}}} &\text{in high frame}\\
   \mu_{\mathbb{E}_{\text{right}}} - \mathbb{E}_{\text{right}}(u) &\text{in low frame}
\end{cases}
 \end{equation}
\noindent We do not model the process of finding a heuristic given an argumentative goal, and therefore this argstrength does not formally depend on the hypotheses defined in Equation \eqref{eq:hypotheses}.

\subsection{Statistical models}

For each of the measures of argumentative strength above, we implement and fit two models:
  \begin{enumerate}
    \item A population model with completely pooled $\alpha$ and $\beta$.
    \item A hierarchical model with by-participant $\alpha$ and $\beta$.
  \end{enumerate}
\noindent The parameter encoding the cost for `none' is always pooled. For the pragmatic argstrength model, we use the same value of $\alpha$ for the calculation of the argumentative strength and for the participant's utility computation.
Parameter recovery simulations on synthesis data for the pooled models and array size $5 \times 12$ show that the $\alpha$, $\beta$, and cost parameters can be recovered accurately from <100 samples for all five models.

\section{Results}\label{sec:results}

Figure~\ref{fig:results-model-comparison} shows the results of loo-based model comparison of all models trained on the dataset.
We can roughly distinguish three levels. 
First, both the pooled and hierarchical vanilla RSA model have a comparatively poor predictive accuracy.
Second, the semantic and pragmatic lr-argstrength models improve over the vanilla RSA model, and perform similarly to each other both for the pooled and the hierarchical cases. 
Third, the maximin and non-parametric models offer the best predictive accuracy.
By expected log-likelihood under leave-one-out cross-validation, the best model is the hierarchical non-parametric model.
However, the second best model, the hierarchical maximin model, is not significantly worse under a simple $z$-test \mf{add reference Lambert}.

Fitting and comparing models on the different matrix sizes conditions independently reveals interesting differences in the best models. 
The maximin model is better than the model-free one for the 5$\times$12 condition, while the opposite is true in the 11$\times$6 and 5$\times$6 conditions. 
The models are not credibly different in the 11$\times$ 12 condition. 
Since we do not expect participants to use different notions of argstrength in the different matrix size condition, these differences in performance might reflect a failure of some linking modeling assumption, e.g., the Binomial likelihood for student results.

The posterior predictive checks for each model show systematic patterns in how they correctly fit or depart from the data, which suggests ways in which the corresponding accounts of argumentative strength succeed or fail in this experimental setup. 
We briefly discuss these qualitative patterns of success and failure for each model. 

\begin{figure}[t]
  \centering
  \includegraphics[width = \linewidth]{pics/model_comparison-combined.pdf}
  \caption{
    Results of model comparison based on the full data set.
    For each model, shapes indicate the expected log-probability mass from leave-one-out cross validation, with error bars showing the standard error of these estimates.
    The $y$-axis lists the different types of models, ordered by ascending goodness-of-fit.
    The shapes and colors indicate the method of model fitting: with or without hierarchical structure.\fc{hierarchic in legend feels unusual to me}
  }
  \label{fig:results-model-comparison}
\end{figure}

%For several of the models, I calculated the posterior predictive p-values for all the models (see Bayesian p-value section above). In all cases they were quite close to 0.5, indicating good compatibility of the data with the fitted posterior. However, note that posterior predictive p-values are generally not uniformly distributed in [0,1] and hierarchical models pose a challenge (see e.g. \href{https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.165.118&rep=rep1&type=pdf}{this paper (clickable)}).

\paragraph{Vanilla RSA} Since this model does not take into account the argumentative goal of participants, it predicts a higher-than-observed frequency of informative but argumentatively weak signals, such as `all|all|wrong' in the high framing condition. It also predicts a lower-than-observed frequency for signals that can be exploited for paltering, such as `some|some|right' in the high condition when most students got all answers wrong.

\paragraph{Lr-argstrength} The simple lr-argstrength and its pragmatic variation make very similar predictions. They capture many patterns of utterance choice in the data relating to argumentativity, e.g., participants' preference for `some|most|right' over `most|all|wrong' in the high frame condition when both utterances are true. However, in the two 12-questions exam conditions, this argstrength predicts a much stronger preference of `some|all|right' over `most|most|right' than we find in the data (in the high frame condition, when both signals are true). This is significant for its overall predictive performance, because these were the most frequently chosen utterances for those conditions.

\paragraph{Maximin argstrength}  Intuitively, what makes 'most|most|right' a better argument than 'some|all|right' in the high frame condition is that the former excludes some particularly bad cases, i.e., where one participant answered correctly and all the other ones got all of them wrong. This is captured by the maximin argstrength, which can fit this pattern in the data better than lr-argstrength.

In each condition, maximin argstrength also predicts a long tail of argumentatively weak signals with equal argstrength, e.g., `some|some|wrong', `all|all|wrong', and several others (in the high condition). This is a surprising prediction, but it makes sense of a pattern in the data: when participants have to describe poor exam results in the high condition, they produce a larger variety of signals than for other observations.

% In the high condition 'most|all|right' is the most produced signal, and it is the best under lr but not maximin (which instead predicts 'all|most|right' to be argumentatively better).

\paragraph{Model free argstrength} In many cases, mf-argstrength makes similar predictions as maximin-argstrength. One exception is that the mf-argstrength model systematically predicts more-than-observed frequency of `all|some|right' in the high condition and `all|some|wrong' in the low condition.

`all|some|right' in $[5,5,5,5,1,1,1,1,1,1,1]$ (narrowLong condition) and 55111 it is better than all other models, which underpredict frequency, but it underpredicts `some|most|right'. The same (but flipped) is true for low in 55511. 

Predicts `all|some|right' better than other modls in 11111 (other models underpredict), and `all|some|wrong' in 55555.

Overpredicts `all|some|wrong' and underpredicts `some|most|wrong' in 55555551111 (low). Overpredicts `all|some|wrong' in 55555555555 (low). Overpredicts `all|some|right' and underpredicts `some|all|right' in 12|12|3|3|3 (high condition).

`most|some|right' in 11111110000 (high condition) is closer to observed for modelfree than other models (but underpredicts some|some|right). Also better for `most|some|right' in 55551110000. 

`most|some|wrong' overpredicted and `some|most|wrong' underpredicted in 12|12|9|3|3 (low)

Overpredicts `some|some|wrong' in 0000... in high, and overpredicts `some|some|right' in 12|12|...|12 in low condition.

Lik maximin, overestimates `all|most|right' in 12|12|12|12|12|12|12|9|9|9|9 (high) and underestimates `most|all|right', same in 12|12|12|9|9 (high).

\paragraph{Overall} Posterior predictive checks also show that all models fail to capture some patterns in the data. All models predict a higher-than-observed frequency for `(some,most,all)|(some,most)|wrong' in the low condition and `(some,most,all)|(some,most)|right' in the high condition (e.g., for state $[1,1,1,0,0]$). In these cases, models distribute their predictions across a larger set of utterance which mostly using adjective `wrong' in the high framing condition and `false' in the low framing condition. It is possible that participants might avoid adjectives that emphasize a polarity opposite to the one for which they are arguing. However, all measures of argumentative strengths we defined are truth-functional, and therefore cannot capture the connotation of conveying the same content in terms of `right' or `false'.

We also observe a much higher frequency of `none|all|right' than predicted by any model. This utterance is chosen in both frame conditions. For example, in the high frame condition, it is chosen for exam results where all students got all answers wrong.\fc{tofinish}

One particularly striking observation is that participants often choose `most|most' when `all|most' would be both more informative and argumentatively stronger according to all models. All models failed to capture this pattern, and indeed it is difficult to explain it as a rational strategic choice. Future work could look into other possible explanations, such as processing ease.

\section{Discussion}\label{sec:discussion}

A crucial empirical observation is that participants prefer `most|most' over `some|all'. A first explanation could be that `most' has a stronger interpretation than assumed in the lr-argstrength model. We implemented models where `most' has a stronger interpretation due to its literal (\fc{cit solt}) meaning or pragmatic interpretation (\fc{self cit}). Neither of these variations were better than the lr-argstrength. 
% Another option is that high enough values of $\gamma$ make `most|most|right' argumentatively stronger than `some|all|right'. We tested a model where (although with a prior that pushed in that direction) $\gamma$ is estimated to be very close to 1 (indeed, so close that most|most| is argumentatively stronger than some|all).
Another potential explanation is that participants allow for more variation across students than assumed by the model. If different students have different binomial parameters, knowing that one student performed very well does not say as much as knowing that many students performed reasonably well, as the former might be a fluke. This would make `some|all' argumentatively weaker. If each student is still described by a Binomial parameter, but these parameters are distributed as a Beta distribution, the resulting model of exam result probabilities follows a Beta-Binomial distribution. We leave a more detailed analysis of this option to future work.

NarrowLong, 1111000..., low condition: Neither model can really make sense of why 'most|all|wrong' is by far the most produced signal. lr-argstrength predicts it should be 'most|all|right' and maximin that it should be 'all|most|wrong'.\fc{tofinish}
  
Lr-argstrength and maximin argstrength differ in how many states are considered when assessing argstrength: all utterance-compatible ones and just one respectively. The truth might lie in the middle. Participants might consider some but not all of the observations for the signal. This behaviour can be rationalized: If the speaker is perfectly rational but reasons about an imperfect listener, they might only focus on the few states that the listener is likely to consider given a signal. We leave a more systematic exploration of this to future work.

\printbibliography

\end{document}
