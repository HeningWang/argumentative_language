\documentclass[10pt,letterpaper]{article}

\usepackage{cogsci}
\usepackage{CSPstyles}

% \cogscifinalcopy %%% Uncomment this line for the final submission

%%% Bibliography %%%
\usepackage[
  style=apa,
  natbib=true,
  annotation=false,
  sortcites=false,
]{biblatex}
\addbibresource{../paper/RSArg.bib} %%% Specify the path to a BibLaTeX file
\setlength{\bibhang}{.125in}

\usepackage{float} %%% Roger Levy added this and changed figure/table placement to [H] for conformity to Word template, though floating tables and figures to top is still generally recommended!

% Sometimes it can be useful to turn off hyphenation for purposes such as spell checking of the resulting PDF.
% \usepackage[none]{hyphenat} %%% Uncomment to turn off hyphenation

%========================================
% Packages
%========================================

% \usepackage{amsmath}
% \usepackage{amsfonts}           % Fonts for Formulas
% \usepackage{amssymb}
% \usepackage{amsthm}
% \usepackage{dsfont}             % double stroke fonts
\usepackage[final]{graphicx}
\usepackage{booktabs}
\usepackage{enumerate}
\usepackage{paralist}

% \usepackage[all]{xy}
\usepackage{url}

\usepackage{gb4e}
\noautomath
\renewcommand{\eachwordtwo}{\relsize{-1}} % format translation in glosses
% \renewcommand{\trans}{\vskip.15\baselineskip\relsize{-1}}
\renewcommand{\trans}{\vskip.15\baselineskip}

\usepackage{lipsum}
% \usepackage{txfonts} % for strict implication symbols
\usepackage{soul}
\usepackage{relsize} % command \relsize{+/-x} for relative font size
% \usepackage[ngerman,english]{babel}
% \usepackage[utf8]{inputenc}
% \usepackage[T1]{fontenc}
\usepackage{xypic}
\usepackage{setspace}
\usepackage{xspace} % for \xspace in definition of acronyms etc.

\DeclareMathOperator{\expo}{exp}
\newcommand{\den}[1]{\ensuremath{[\![#1]\!]}}
\newcommand{\interpret}[1]{\ensuremath{\den{#1}}}

\newcommand{\hw}[1]{\textcolor{glaucous-bright}{[HW: #1]}}
\newcommand{\mf}[1]{\textcolor{shimmer-main}{[MF: #1]}}
\newcommand{\fc}[1]{\textcolor{opal-bright}{[FC: #1]}}
\DefineNamedColor{named}{mycol2}{cmyk}{0.8,0,0.8,0.2}
\newcommand{\mycolh}[1]{{\textcolor{mycol2}{#1}}}
\newcommand{\mymark}[1]{{\color{mycol}{#1}}}

% margin lines for drafty passages
\usepackage{mdframed}
\newmdenv[
  topline=false,
  bottomline=false,
  rightline=false,
  linecolor=gray,
  linewidth=1pt,
  skipabove=\topsep,
  skipbelow=\topsep
]{draftytext}


\title{RSArg}

%%% Format authors using helper functions from authblk package %%%
\author[1]{\mbox{Author N. One (a1@uni.edu)}}
\author[2]{\mbox{Author Number Two}}
\affil[1]{Department of Hypothetical Sciences, University of Illustrations}
\affil[2]{Department of Example Studies, University of Demonstrations}

%%% Or, format authors manually %%%
% \author{
%   {\large\bfseries Author N. One (a1@uni.edu)$^1$ \& Author Number Two$^2$} \\
%   {\normalsize\normalfont
%     $^1$Department of Hypothetical Sciences, University of Illustrations \\
%     $^2$Department of Example Studies, University of Demonstrations
%   }
% }

\begin{document}


\maketitle


\noindent
\hspace*{0.33\linewidth}%
\parbox{0.66\linewidth}{%
  \itshape
  \footnotesize
  ``Today in Timiryazevsky Park [two] world leaders participated in a 100 meter foot race.
      Our Soviet Premier, Nikita Khrushchev, finished a very respectable second place.
      The poor American President, John F.~Kennedy finished a miserable next-to-last.'' \\
      \hfill --- \textcolor{gray}{ascribed to Russian newspaper \textit{Pravda}}
}

\bigskip


  % \begin{footnotesize}
  %   \begin{quote}
  %     \noindent
  %     % \textbf{A Foot Race In Moscow Between World Leaders.}
  %     Today in Timiryazevsky Park [two] world leaders participated in a 100 meter foot race.
  %     Our Soviet Premier, Nikita Khrushchev, finished a very respectable second place.
  %     The poor American President, John F.~Kennedy finished a miserable next-to-last. \\
  %     \hfill (\textcolor{gray}{[ascribed to newspaper \textit{Pravda}\footnote{Taken from: \url{https://www.linkedin.com/pulse/foot-race-between-john-f-kennedy-nikita-khrushchev-tom-salamone}}]})
  %   \end{quote}
  % \end{footnotesize}



\begin{abstract}
  Concrete.

\textbf{Keywords:}
pragmatic language use;
argumentative framing;
argument strength;
probabilistic modeling;
\end{abstract}

\section{Introduction}
\label{sec:introduction}

Overwhelming evidence from decades of research demonstrates that human language use is often strongly oriented towards providing a high degree of useful information for addressees \mf{REFs}.
This picture aligns well with the classic Gricean framework \citep{Grice1975:Logic-and-Conve}, which posits a cooperative principle alongside Maxims of Quality (truth), Quantity (informativity), and Relevance---where the latter is typically interpreted as relevance to the listener.

Formal models of pragmatic language use consequently often rely on some kind of formal, relative, or quantitative notion of informativity, versions of which are supplied by formal logic (e.g., asymmetric logical entailment) or information theory.
Based on such formalized quantitative notions of informativity, we can describe speakers' pragmatic choice of expressions as a form of utility maximization, defined---at least in part---by the drive to optimize relevant information exchange \citep{Parikh1991:Communication-a,BlutnerBOTJoS2000}.

However, human talk does not always revolve around the straightforward exchange of relevant information alone.
We also express an interpretative stance towards the facts we describe, communicating sentiment and opinion alongside descriptions of the world.
Indeed, some work suggests that human talk is much more about persuasion, argumentation, manipulation, and opinion-negotiation than about pure, objective---indeed, robot-like---information-sharing \citep{AnscombreDucrot1983:Largumentation-,MercierSperber2011:Why-do-humans-r,Enfield2024:Language-vs.Rea}.
For example, as a case of selective truth-telling, or \emph{paltering} \citep{RogersZeckhauser2017:Artful-palterin}, the same outcome of an exam could be truthfully described in a way that makes the students appear successful or less successful overall:

\begin{exe}
  \item
  \begin{xlist}
    \item Most of the students got most questions right.
    \item Some of the students got all questions wrong.
  \end{xlist}
\end{exe}

Yet, there is much less formal work on this kind of language use.
What seems to be blatantly lacking are good formal descriptions of what makes one utterance more suitable than another for a speaker with an intent to argumentatively frame their contribution.
In this work, we therefore ask which kind of utility function might underlie a speaker's choice to prefer one utterance over another in a persuasive or argumentative context: how can we capture formally what makes one argument better than another?
We address this question through the notion of \emph{argumentative strength}.

Some prior work \citep[e.g.,][]{Merin1997:If-all-our-argu,Rooijvan-Rooij2004:Cooperative-ver,CumminsFranke2021:Rational-interp} suggests a formalization of argumentative strength in terms of \textit{log-likelihood ratios}, based on early work from the philosophy of science on observational evidence \citep{Good1950:Probability-and}; see the formalization below.
However, so far there has been no stringent empirical testing of this notion, nor a systematic comparison against closely related competitor notions in terms of their predictive accuracy for experimental data.
Providing such a comparison is the main contribution of this work.

We focus on a setting of selective truth-telling, or paltering \cite{Roberts}.
We study cases similar to the real-life examples examined by \citet{CumminsFranke2021:Rational-interp}, but consider a constrained experimental setting that allows statistical model comparison of bespoke probabilistic models which differ only in the quantitative notion of argumentative strength they assume underlies the speakers' choice of expression.
In the following, we formulate these models in the tradition of the RSA framework \cite{RSA}.
Next, we describe the experimental set-up, and report on the statistical model comparisons, as well as our results.
Our main findings are that \mf{fill me \dots}.


\section{Probabilistic models of argumentative language}
\label{sec:prob-pragm}

Probabilistic models of pragmatic reasoning usually define a speaker and listener policy.
Here, we will focus exclusively on the speaker's policy.
In line with the usual assumption of Bayesian decision-makers, the speaker's policy of choosing an utterance $u$, when trying to communicate a state $s$ is defined in terms of a soft-max operation \citep{FrankeDegen2023:The-softmax-fun}, with parameter $\alpha$ on the utility function $U(u,s)$:
\begin{align}
  \label{eq:S1}
  P_{S} (u \mid s) & \propto \expo\left( \alpha U( u , s ) \right)\,.
\end{align}
The utility function $U(u,s)$ captures how good it is for the speaker to choose $u$ when the true state, according to the speaker, is $s$.
We here follow the Rational Speech Act (RSA) modeling framework \citep[e.g.,][]{FrankGoodman2012:Predicting-Prag,Degen2023:The-Rational-Sp} which adopts the usual Gricean assumptions that the speaker wants to speak truly, maximize the amount of information conveyed about the state $s$, and to minimize their own speaking effort \citep{Grice1975:Logic-and-Conve}.
To implement these assumptions, utilities are defined as a sum of the information-theoretic surprisal of $s$ conditional on $u$ being true and the (negative) cost of $u$, which is a stand-in for production effort or ease of accessibility:
\begin{align}
  \label{eq:util-vanilla}
  U(u , s) &= \log P(s \mid \interpret{u}) - \text{cost}(u)\,,
\end{align}
where $\interpret{u} \subseteq S$ is the semantic denotation of $u$, formally represented as the set of world states in which $u$ is true.
Under the wide-spread assumption of a flat prior over $s$, the conditional probability of $s$ given that $u$ is true can be written as:
\begin{align*}
P(s \mid \interpret{u})
    &=
    \begin{cases}
        |\interpret{u}|^{-1} & \text{if } s \in \interpret{u} \\
        0 & \text{otherwise.}
    \end{cases}
\end{align*}
With this, if the semantics for utterances is binary, the utility function from above can be factored into three well-known aspects of pragmatic language generation, namely the requirements that the speaker's utterance be true, informative and economical \citep{ScontrasTessler2021:A-practical-int}:
\begin{align*}
  U(u , s) &=
             \underbrace{\log \left[ s \in \interpret{u} \right]}_{\text{truth}}
             \ + \
             \underbrace{\log \interpret{u}^{{-1}}}_{\text{informativity}}
             \ - \
             \underbrace{\text{cost}(u)}_{\text{economy}} \,.
\end{align*}

The speaker's policy defined above in Equation~\eqref{eq:S1}, when used with the standard utility function in Equation~\eqref{eq:util-vanilla} has been productively used to explain choices of utterances for different linguistic constructions of phenomena, e.g., for referential expressions \citep{FrankGoodman2012:Predicting-Prag}, generics \citep{Tessler2019:The-Language-of}, conditionals \citep{GrusdtLassiter2021:Probabilistic-m}, quantifiers and implicature \citep{GoodmanStuhlmuller2013:Knowledge-and-I,Tielvan-TielFranke2021:Probabilistic-p}, gradable adjectives \citep{LassiterGoodman2015:Adjectival-vagu}, or probability expression \citep{HerbstrittFranke2019:Complex-probabi}.
\mf{insert some more references (without MF as co-author!)}
Yet, some phenomena seem to require more elaborate utility functions.
For example, in the realm of social meaning, extensions of the vanilla RSA model sketched above have been explored which incorporate additional utility components related to politeness \citep{YoonTessler2020:Polite-Speech-E}.
Here, we take a similar approach to modelling the utility trade-off between describing the world informatively and making an argument in favor of a position or hypothesis $H_{0}$, as opposed to the competing position or hypothesis $H_{1}$.
The general form of the extended speaker utility function we consider in this paper will be:
\begin{align}
  & U(u , s , H_{0} , H_{1}) =  \label{eq:utilArgstrength} \\  \nonumber
  & \underbrace{{\mycolh{\beta}} \ \log P_{L_0} (s \mid \interpret{u})}_{\text{truth \& informativity}}
 \  + \
      \underbrace{(\mycolh{1-\beta}) \ \text{argstr}(u, H_{0} , H_{1})}_{\text{argumentative strength}}
 \ - \
    \underbrace{\text{cost}(u)}_{\text{economy}}
\end{align}
Following the previous literature, the parameter $\beta$ models the degree to which a speaker values optimizing informativity of an utterance or making a strong argument for position $H_{0}$ (relative to $H_{1}$).
For the special case of $\beta = 1$, this formulation reduces to the previous utility function which did not have argumentative strength as an additional speaker objective for utterance selection.

In the following we will explore different models of the speaker's utterance choice:
\begin{enumerate}
  \item The \textbf{vanilla RSA model} provides the conservative baseline. It contains no speaker objective for argumentative speech; alternatively we can think of it as a model with $\beta=1$.
  \item The \textbf{likelihood-ratio model} assumes that argumentative strength can be operationalized in analogy to a common measure of observational evidence, the log-likelihood ratio (based on literal interpretation of the utterance).
  \item The \textbf{pragmatic likelihood-ratio model} is similar to the previous model but computes argumentative strength via log-likelihood ratios based on a pragmatic enrichment of the utterance.
  \item  The \textbf{maximin model} provides a computationally simpler definition of argumentative strength in terms of a form of worst-case reasoning.
  \item The \textbf{model-free model} uses a situation-specific notion of argumentative strength in terms of the posterior expectation of true answers; this approach is ``model-free'' in the sense that it does not commit to a strong theoretic position on what argument strength is supposed to be.
\end{enumerate}

\begin{draftytext}
  \begin{itemize}
    \item will explore a bunch of notions
    \item the starting point is log likelihood ratio
    \item used by a lot of previous work
    \item but no real quantitative model fits so far
  \end{itemize}
\end{draftytext}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiment}
\label{sec:experiment-1}

To test whether and how speakers choose expressions to frame a complex situation with argumentative information culling, we used an experimental design which presents a perspicuous but complex state of affairs (the results of a high-school exam) and allows participants to choose flexibly from a larger, but still constrained set of alternative expressions.
The design used here is essentially the same as that of Experiment~1 reported in \citep{Vinicius-Macuch-SilvaWinter2024:Strategic-use-o}, except that we here used a larger set of visual scenes (different array sizes, see below).
While the work reported by \citet{Vinicius-Macuch-SilvaWinter2024:Strategic-use-o} also elicited and analyzed free production data, we here focus on a more constrained free-choice task in order to harness the complexity of the data for subsequent modeling.
Participants could essentially choose one of 32 sentences, but they did so by selecting, using a drop-selection menu, (i) an outer quantifier, (ii) an inner quantifier, and (iii) an adjective, to complete the sentence frame in (\ref{bsp:sentences-Exp}).

\begin{exe}\ex \label{bsp:sentences-Exp}
OQ of the students got IQ of the questions ADJ
\end{exe}
with OQ and IQ $\in \{$ None, Some, Most, All $\}$, and ADJ $\in \{$ right, wrong $\}$.

\paragraph{Participants.}
A total of $N=201$ participants were recruited via Prolific (self-identified gender: 88 female, 111 male, 1 other and 1 non-disclosed; mean age (of those who revealed it) 30.3 (standard deviation 8.07), min 18 and max 60).
Participants had to be at least 18 years old in order to participate.
They were paid £1.5.
Based on a mean completion time of just below 10 minutes (median just below 9 minutes), this amounted to an average hourly payment of £1.5.
\mf{check: no other Prolific internal selection criteria; English etc.?}\fc{We only excluded participants with more than 4 false responses}

\paragraph{Materials.}
The results of high-school exams were presented visually in form of matrices, as shown in Figure~\ref{fig:overview} (top left).\fc{Figure is missing}
The rows of matrices corresponded to students (indicated by names), the columns indicated questions.
A checkmark on green background in a cell represented that the student got the question right.
A cross on a red background represented a false answer.
The results where always arranged to show students ordered in terms of performance (students with more correct answers on in higher rows).
The names of students were sampled at random for each trial from a list of common English first names.

Four sizes of matrices were used, differing in the number of students (5 or 11) and the number of questions in the exam (6 and 12).
For example, the matrix in Figure~\ref{fig:overview} is an instance of a $5 \times 12$ matrix.
For each matrix size, there were 20 instances, each one corresponding to one of the 20 situations which can be logically distinguished based on sentences of the form in (\ref{bsp:sentences-Exp}).
More concretely, the 20 situations are all the ``possible world states'' that can be differentiated with a language that contains only the sentences in (\ref{bsp:sentences-Exp}) under their standard logical meaning, assuming that \textit{some} means \textit{at least one} and \textit{most} means \textit{more than half} \citep[see][for details]{Vinicius-Macuch-SilvaWinter2024:Strategic-use-o}.

\paragraph{Procedure.}
The experiment started with an explanation of the displays and the task.
Participants were instructed to describe the results of high-school exams as either favorable or disfavorable (high vs.~low framing condition).
Each participant consistently saw one size of the four results matrices, and they saw each one of the 20 instances of that matrix type exactly once in completely randomized order.
Trials were randomly assigned to a high or low framing condition, so that each participant saw 10 trials in the high and 10 trials in the low framing condition.

\paragraph{Results.}
Following preregistered protocol, we excluded all the data from a participant if the participant selected the same response in all trials or if the participant gave more than four responses which are literally false as a description of the results shown in the corresponding trial.
This reduced the original number of $N=201$ participants to $N=186$.
We also excluded any remaining responses that are literally false.
This resulted in another $113$ individual responses being removed from the data set.

Figure~\ref{fig:results-exp1} shows the proportions of sentences which participants generated as descriptions for the exam results.
The plot differentiates the two different argumentative framing conditions (\textit{high} vs.~\textit{low}, indicated by color in Figure~\ref{fig:results-exp1}), and the four different shapes of the results matrices to be described (different rows in the figure).
Visually, the distributions for different matrix sizes seem to be rather similar, but there appear to be striking contrasts in the choices of descriptions between the two different argumentative framing conditions.
This impression is corroborated by a simple $\chi^{2}$-test.
The choice distributions seem to differ between results matrices ($\chi^{2} \approx 216.8$, $\text{df}=168$, $p < 0.006$).
The \textit{high} vs.~\textit{low} framing induced significantly different distributions over descriptions ($\chi^{2} \approx 2300.7$, $\text{df}=103$, $p < 2e^{-16}$).
The latter result, indicating a difference between \textit{high} and \textit{low} argumentative framing conditions, suggests that our manipulation worked and that participants are indeed able to adapt their description choices to the strategic argumentative framing the context demanded.


\begin{figure*}[t]
  \centering
  \includegraphics[width=1.0\textwidth]{../data/pics/barplot_responses_perConditions.pdf}
  \caption{
    Proportion of sentences generated in Experiment~1.
    The bars show the observed proportions of sentences generated by the participants using the template in (\Ref{bsp:sentences-Exp}).
    Each row shows the results for a different matrix size.
  }
  \label{fig:results-exp1}
\end{figure*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Statistical Analysis}
\label{sec:models}

We perform a Bayesian analysis of the data produced by the experiment, using the RSA speaker defined in Eq.~\ref{eq:S1} as a generative model of participants' production behaviour. A full implementation of argumentative strength (Eq.~\ref{eq:utilArgstrength}) requires the specification of one hypothesis that the speaker argues for ($H_0$) and one that they argue against ($H_1$), as well as a functional form that measures how strongly a specific utterance supports $H_0$ against $H_1$.

\subsection{Hypotheses for argstrength calculation}

We model each hypothesis $H$ as saying that all students in the class have a certain probability $\gamma_H$ of getting each answer correct, making the simplifying assumption that there is no variation in skill across students and no variation in probability of getting different answers correct. 
\fc{I actually spent a long time in the early phases of the project exploring variations of this - not sure it makes sense to pick up this thread though.}
The probability of observing 	the results for a class is then proportional to the product of the Binomial probability of each student's results:
  %
  \begin{equation}\label{eq:stateprob}
    P(s \mid \gamma_H) \propto \prod_{k \in s}{ 12 \choose k } \gamma_H^k (1-\gamma_H)^{12-k}
  \end{equation}
  %
where $S$ is the set of exam arrays participants can observe in the experiment and each exam is encoded as a list of numbers of correct answers.

For the models below, the hypotheses are:
 \begin{align}\label{eq:hypotheses}
\gamma_{H_0} &= 0.85 &\gamma_{H_1} &= 0.15 & \text{for high frame condition.} \\
\gamma_{H_0} &= 0.15 &\gamma_{H_1} &= 0.85 & \text{for low frame condition.}\nonumber
 \end{align}
Intuitively, in the high framing condition the speaker is choosing an utterance to support the hypothesis that students had a high probability of answering correctly rather than a low probability, and the opposite is true in the low framing condition. 

\subsection{Form of the argstrength function}

Having defined the two hypotheses, we next turn to various ways of specifying the functional form of the argumentative strength of utterances.

\paragraph{Log likelihood ratio argstrength.} The starting point is the notion of \emph{weight of evidence}, which has been introduced in the previous literature as a formal notion of argument strength, following \mf{refs}.
%This notion requires fixing two competing hypotheses $H_{0}$ and $H_{1}$ and formalizes the argumentative strength of an utterance $u$ as evidence in favor of $H_{0}$ as opposed to the (alternative, competing) hypothesis $H_{1}$.
Concretely, we consider the degree to which the utterance $u$ is more likely to be true (literally) under hypothesis $H_{0}$ than under a competing (alternative) hypothesis $H_{1}$:
%
\begin{equation}
    \text{lr-argstr}(u, H_0, H_1) = 
    \log \frac{P( \interpret{u} \mid H_0 ) }{ P( \interpret{u} \mid H_1 ) }
\end{equation}
%
\noindent where $P( \interpret{u} \mid H )$ is the probability that utterance $u$ is \emph{true} (rather than e.g., produced) given hypothesis $H$. $P(\interpret{u} \mid H)$ can be calculated based on the literal semantics:
\begin{equation}
    P(\interpret{u} \mid H) = \sum_{s \in S} \interpret{u}^s P(s \mid \gamma_H)
\end{equation}
where $P(s \mid \gamma_H)$ is defined in Eq.~\ref{eq:stateprob}, and $\interpret{u}^s$ equals 1 if $u$ is true in $s$ and 0 otherwise.

\paragraph{Pragmatic argstrength.} The second type of argstrength replaces truth in a state $ \interpret{u}^s$ with the probability of production by a pragmatic speaker:
\begin{equation}
\textrm{prag-argstr}(u, H_0, H_1) = \log \frac{P_{S} (u \mid H_0)}{P_{S} (u \mid H_1)}
\end{equation}
\noindent where:
\begin{equation}
P_{S} (u \mid H) = \sum_{s \in S} P_{S} (u \mid s) P(s \mid \gamma_H)
\end{equation}
and $P_{S}$ is the pragmatic speaker defined above in Equation~\eqref{eq:S1}, who does not in turn consider argumentative strength.

\paragraph{Maximin argstrength.} The third type of argstrength captures the intuition that, rather than calculating argumentative strength by marginalizing across \emph{all} the states compatible with the utterance $u$, participants only consider the argumentatively weakest state compatible with $u$:
  \begin{equation}
    \text{maximin-argstr}(u, H_0, H_1) =
      \min_{s \in \interpret{u}} \log \frac{p( s \mid \gamma_{H_0})}{p( s \mid \gamma_{H_1})} 
  \end{equation}
A speaker might use maximin-argstr when considering the worst case scenario for a listener who guesses a single one of the states compatible with the utterance. In the experiment, for utterance `all|some|right', this would be state $[3,3,3,3,3]$ in the high framing and $[12,12,12,12,12]$ in the low framing. Maximin-argstr can also be motivated on computational grounds, since it only requires the search for the single argumentatively weakest state, which in some cases can be done efficiently. Maximin- and lr-argstrength differ in terms of the absolute argstrength of signals, and in some cases also in their ranks. For instance, in the high framing condition `most|none|wrong' is better than `all|most|right' for lr-argstr, but the other way around for maximin-argstr.

\paragraph{Model-free argstrength.} The final type of argstrength depends on the mean number of right answers across states compatible with the utterance:
\begin{equation}
    \mathbb{E}_{\text{right}}(u) = |\interpret{u}|^{-1} \sum_{s \in \interpret{u}} \sum_{i \in s} i 
 \end{equation}
This argstrength then encodes the (centered) mean number of right answers in the high frame condition, and the opposite in the low frame condition, given the utterance:
\begin{equation}
\text{mf-argstrength}(u) = 
\begin{cases}
    \mathbb{E}_{\text{right}}(u) - \mu_{\mathbb{E}_{\text{right}}} &\text{in high frame}\\
   \mu_{\mathbb{E}_{\text{right}}} - \mathbb{E}_{\text{right}}(u) &\text{in low frame}
\end{cases}
 \end{equation}
\noindent 

\subsection{Statistical models}

For each of the measures of argumentative strength above, we implement and fit two models:
  \begin{enumerate}
    \item A population model with completely pooled $\alpha$ and $\beta$.
    \item A hierarchical model with by-participant $\alpha$ and $\beta$ (For the pragmatic argstrength model, we pool the value of $\alpha$ for the calculation of the argumentative strength and of the utility).
  \end{enumerate}
\noindent The parameter encoding the cost for `none' is always pooled.

\section{Results}
\label{sec:results}

Figure~\ref{fig:results-model-comparison} shows the results of loo-based model comparison.
By expected log-likelihood under leave-one-out cross-validation, the best model is the hierarchical non-parametric model.
However, the second best model, the hierarchical maximin model, is not significantly worse under a simple $z$-test \mf{add reference Lambert}.

\begin{figure*}[t]
  \centering
  \includegraphics[width = 0.7\textwidth]{pics/model_comparison-combined.pdf}
  \caption{
    Results of model comparison based on the full data set.
    For each model, shapes indicate the expected log-probability mass from leave-one-out cross validation, with error bars showing the standard error of these estimates.
    The $y$-axis lists the different types of models, ordered by ascending goodness-of-fit.
    The shapes and colors indicate the method of model fitting: with or without hierarchical structure.
  }
  \label{fig:results-model-comparison}
\end{figure*}

For several of the models, I calculated the posterior predictive p-values for all the models (see Bayesian p-value section above). In all cases they were quite close to 0.5, indicating good compatibility of the data with the fitted posterior. However, note that posterior predictive p-values are generally not uniformly distributed in [0,1] and hierarchical models pose a challenge (see e.g. \href{https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.165.118&rep=rep1&type=pdf}{this paper (clickable)}).

It is also instructive to have a look at the \emph{pointwise} posterior predictive p-values.
- Roughly, they quantify the compatibility of the model with each individual datapoint.
- They answer the question "What is the probability that the posterior prediction for this specific datapoint has an equal or higher discrepancy than the actually observed one?"
- In this case, the measure of discrepancy is just the likelihood.
- The odd thing is that many datapoints have pointwise posterior predictive p-value of 1.
- This means that the real datapoint has a probability greater than or equal to the one sampled from the posterior *for all trace samples*.
- Note however that in the case of a categorical distribution, the 'equal to' can do a lot of work.
- In particular, if the posterior samples the same factor as the original data, they will always have the same likelihood.
- This will happen if the model across the trace gives a high probability to the specific datapoint that was observed.
- So it's not so worrying.
- Pointwise predictive values close to 1 however indicate low compatibility of the model and the data.

\paragraph{lr-argstrength} Looking at the datapoints that the different models fail to predict reveals some illuminating patterns. For the lr-argstrength model, we look at the signals that were produced most often by participants for a certain observation but which are not on the Pareto frontier of informativity/lr-argstrength, which means that no value of $\beta$ could account of them. These are:
\begin{itemize}
  \item Observation 4 ([12, 12, 9, 0, 0]), high condition:
  \begin{itemize}
    \item Optimal signal: 'some|all|right' (5 times)
    \item Most common signal: 'most|most|right'
  \end{itemize}
  \item Observation 10 ([12, 12, 3, 0, 0]), low condition:
  \begin{itemize}
    \item Optimal signal: 'some|all|wrong' (7 times)
    \item Most common signal: 'most|most|wrong' (15 times)
  \end{itemize}
  \item Observation 15 ([12, 12, 9, 3, 3]), high condition:
  \begin{itemize}
    \item Optimal signal: 'some|all|right' (14 times)
    \item Most common signal: 'most|most|right' (20 times)
  \end{itemize}
  \item Observation 16 ([12, 12, 9, 9, 9]), high condition:
  \begin{itemize}
    \item Optimal signal: 'some|all|right' (8 times)
    \item Most common signal: 'most|most|right' (11 times)
  \end{itemize}
  \item Observation 19 ([9, 9, 3, 0, 0]), low condition:
  \begin{itemize}
    \item Optimal signal: 'some|all|wrong' (7 times)
    \item Most common signal: 'most|most|wrong' (11 times)
  \end{itemize}
\end{itemize}
(Note: there are other ways in which the predictions differ from observations, e.g. often signals on the Pareto frontier are not produced as often as one would expect.) They all involve 'most|most| ' being used when 'some|all| ' is predicted to be a better signal by the model!

There is an intuition:  what makes 'most|most|right' a better argument than 'some|all|right' is that the former excludes some particularly bad cases (namely, the case where one participant answered correctly and all the other ones got all of them wrong).

\paragraph{maximin argstrength}  Maximin argstrength makes better predictions than lr-argstrength in several instances:
\begin{itemize}
    \item '1.png' and '3.png', low condition: The most produced signal ('most|all|wrong') is the best for maximin but not for BF (although still close to best).
    \item  '2.png', low condition and '13.png' high condition: As I mentioned above, maximin makes sense of why so many different signals were produced.
    \item '4.png' and '15.png', high condition:  The most produced signal ('most|most|right') is best for maximin but not for BF.  Neither argstrength explains why 'some|none|right' was not produced more, but the cost for 'none' might.
    \item '8.png', high condition: The most produced signal ('all|most|right') is best for maximin but not for BF.
    \item '9.png' and '14.png', low condition: The most produced signal ('all|most|wrong') is best for maximin but not for BF.
    \item '10.png' and '19.png', low condition: The most produced signal ('most|most|wrong') is best for maximin but not for BF.
  \end{itemize}

Maximin argstrength also predicts that a lot of the `bad' signals (given the condition) are equally bad, e.g., 'some|some|wrong' and 'all|all|wrong' (in the high condition). On the other hand, with lr-argstrength 'all|all|wrong' is a bad signal and but 'some|some|wrong' is neutral (neither good nor bad). This might seem like a weird prediction of maximin at first, but interestingly it makes sense of a part of the data that was puzzling before.
 % which can be seen by comparing figures '13.png' of 'by\_observation\_maximin\_argdelta' and 'by\_observation\_argdelta'. Not just  ('some|some|wrong') but also (e.g. 'none|all|right')
 When participants are forced to describe a 'bad' situation in the high condition, they don't just produce the 'winner' according to BF-argstrength, but rather produce a larger variety of signals than for other observations. 
 
On the other hand, maximin argstrength underpredicts the frequency of 'some|some|wrong'. The truth might lie in the middle. Participants might consider some but not all of the observations for the signal. This behaviour can be rationalized: If the speaker is perfectly rational but reasons about an imperfect listener, they might only focus on the few states that the listener is likely to consider given a signal.

In some cases, maximin-argstrength makes worse predictions than lr-argstrength.  '5.png', high condition: 'most|all|right' is the most produced signal, and it is the best under lr but not maximin (which instead predicts 'all|most|right' to be argumentatively better). '14.png', high condition: a signal that is predicted to be good by maximin ('none|all|wrong') is not produced much. This can be explained by the cost for 'none'.

\section{Discussion}
\label{sec:discussion}

  \begin{itemize}
    \item There are a couple of implementation decisions for this model (and all the following ones):
    \item Whether to consider all \emph{possible} observations (every way that 5 students can answer 12 questions) or just the 20 observations that were presented in the model. I call the former the 'Michael method' in the code and the latter is the one I am implementing for simplicity, because it allows me to simply manipulate arrays and keep everything vectorized.
    \item Whether to give a small fuzzy truth value to utterances that are literally false or treat them as just having truth value 0. The former is the method I use here (though see the calculation below in the model with Solt's 'most'), the latter is the one used in the original Greta implementation.
  \end{itemize}

An interesting empirical observation is that participants prefer `most|most' over `some|all'. A first explanation could be that `most' has a stronger interpretation than assumed in the lr-argstrength model. Then, `some' becomes weaker than `most' and `some students got all answers wrong' could be argumentatively weaker than `most students got most of the answers wrong'. We played with several variations of this idea that increases the argumentative strength of utterances involving 'most':
\begin{itemize}
  \item Calculate with pragmatic argumentative strength using S1.
  \item Give a stronger literal meaning (based on Solt's account of 'most')
  \item Use a 'manually' pragmatically enriched sense of 'most' (based on my paper with Jakub).
\end{itemize}
None of these variations were better than the lr-argstrength.

Another option is that high enough values of $\gamma$ make `most|most|right' argumentatively stronger than `some|all|right'. We tested a model where (although with a prior that pushed in that direction) $\gamma$ is estimated to be very close to 1 (indeed, so close that most|most| is argumentatively stronger than some|all).

A third option lifts the assumption in the originl model of a single binomial parameter for all students. If different students have different binomial $p$ parameters (e.g. structured hierarchically), knowing that one student performed very well does not tell you as much as knowing that many students performed reasonably well, as the former might be a fluke, making `some|all' weaker. If each student is still described by a Binomial parameter, but these parameters are distributed as a Beta distribution, the resulting model of exam result probabilities follows a Beta-Binomial distribution. We leave a more detailed analysis of this option to future work.

Some observations remain puzzling. 
  - '17.png': low condition: Neither model can really make sense of why 'most|all|wrong' is by far the most produced signal. lr-argstrength predicts it should be 'most|none|right' and maximin that it should be 'all|most|wrong'.
  - '16.png', high condition: Really strange, because it seems like there's no way of cashing out argumentative strength where 'most|most|right' is better than 'all|most|right' in the high condition.

\printbibliography

\end{document}
