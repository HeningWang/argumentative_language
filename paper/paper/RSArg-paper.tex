\documentclass[fleqn,reqno,10pt]{article}

\include{preamble}

\newcommand{\interpret}[1]{\ensuremath{\den{#1}}}

\newcommand{\hw}[1]{\textcolor{glaucous-bright}{[HW: #1]}}
\newcommand{\FC}[1]{\textcolor{opal-bright}{[FC: #1]}}


\title{RSArg}
\author{}
\date{}

\begin{document}
\maketitle

\begin{itemize}
  \item intro:
  \begin{itemize}
    \item pragmatics mostly on cooperative dialogue
    \item much less on argumentative language use; and what exists is often informal \citep{AnscombreDucrot1983:Largumentation-}
    \item problem: what's the goal of argumentative language use (what's the payoff function?)
  \end{itemize}
  \item probabilistic pragmatics / RSA:
  \begin{itemize}
    \item vanilla version
    \item extensions with multiple utility components
    \item sketch idea of adding some notion of argumentative strength to utils
    \item mention log-odds ratio as an obvious candidate but postpone full model and definition of $argStr(u)$ until after the experimental part
  \end{itemize}
  \item Exp 1 \& 2 (in one swoop):
  \begin{itemize}
    \item describe experimental design
    \item mention (e.g., in footnote and expand in appendix) what was preregistered when
    \item report on results w/ visuals and some descriptive stats showing the “argumentativity matters”
  \end{itemize}
  \item Models:
  \begin{itemize}
    \item describe different RSArg models, expand on argStr(u)
    \item maybe: motivate models with reference to some aspect of the observed data
  \end{itemize}
  \item Model fits \& comparison:
  \begin{itemize}
    \item describe Bayesian models (hierarchical models, priors etc.)
    \item discuss results of model fits and comparison
  \end{itemize}
  \item Discussion
\end{itemize}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.95\textwidth]{pics/overview.png}
  \caption{
    We investigate speakers' flexibly to strategically choose expressions to present a complex situation, like the results of an exam, in a way that makes it appear more positive or more negative, e.g., implying more of a high or a low success rate of the exam.
    Our main research questions are: (1) whether speaker are able to systematically engage in strategic ``information culling'' to achieve argumentative framing; and (2) which objective function best characterizes speakers' aggregate behavior, i.e., what is it that speaker \textit{do} when try to frame a situation in one way or another.
    To address these questions, we compare a number of probabilistic models based on their ability to explain the experimental data.
    Models differ in the way in which they operationalize the argumentative strength of an expression.
    \mf{improve visualization}
  }
  \label{fig:overview}
\end{figure}

\mf{comment by Michael}
\hw{comment by Hening}
\FC{comment by Fausto}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Probabilistic pragmatics \& and argumentative discourse}
\label{sec:prob-pragm}

Probabilistic models of pragmatic reasoning usually define a speaker and listener policy.
Here, we will focus exclusively on the speaker's policy.
In line with the usual assumption of Bayesian decision-makers, the speaker's policy of choosing an utterance $u$, when trying to communicate a state $s$ is defined in terms of a soft-max operation \citep{FrankeDegen2023:The-softmax-fun}, with parameter $\alpha$ on the utility function $U(u,s)$:
\begin{align}
  \label{eq:S1}
  P_{S} (u \mid s) & \propto \expo\left( \alpha U( u , s ) \right)\,.
\end{align}
The utility function $U(u,s)$ captures how good it is for the speaker to choose $u$ when the true state, according to the speaker, is $s$.
We here follow the Rational Speech Act (RSA) modeling framework \citep[e.g.,][]{FrankGoodman2012:Predicting-Prag,Degen2023:The-Rational-Sp} which adopts the usual Gricean assumptions that the speaker wants speak truly, maximize the amount of information conveyed about the state $s$, and to minimize their own speaking effort \citep{Grice1975:Logic-and-Conve}.
To implement these assumptions, utilities are defined as a sum of the information theoretic surprisal of $s$ conditional on $u$ being true and the (negative) cost of $u$, which is a stand-in for production effort or ease of accessibility:
\begin{align}
  \label{eq:util-vanilla}
  U(u , s) &= \log P(s \mid \interpret{u}) - \text{cost}(u)\,,
\end{align}
where $\interpret{u} \subseteq S$ is the semantic denotation of $u$, formally represented as the set of world states in which $u$ is true.
Under the wide-spread assumption of a flat prior over $s$, the conditional probability of $s$ given that $u$ is true can be written as:
\begin{align*}
P(s \mid \interpret{u})
    &=
    \begin{cases}
        |\interpret{u}|^{-1} & \text{if } s \in \interpret{u} \\
        0 & \text{otherwise.}
    \end{cases}
\end{align*}
With this, if the semantics for utterances is binary, the utility function from above can be factored into three well-known aspects of pragmatic language generation, namely the requirements that the speaker's utterance be true, informative and economical \citep{ScontrasTessler2021:A-practical-int}:
\begin{align*}
  U(u , s) &=
             \underbrace{\log \left[ s \in \interpret{u} \right]}_{\text{truth}}
             \ + \
             \underbrace{\log \interpret{u}^{{-1}}}_{\text{informativity}}
             \ - \
             \underbrace{\text{cost}(u)}_{\text{economy}} \,.
\end{align*}


The speaker's policy defined above in Equation~\eqref{eq:S1}, when used with the standard utility function in Equation~\eqref{eq:util-vanilla} has been productively used to explain choices of utterances for different linguistic constructions of phenomena, e.g., for referential expressions \citep{FrankGoodman2012:Predicting-Prag}, generics \citep{Tessler2019:The-Language-of}, conditionals \citep{GrusdtLassiter2021:Probabilistic-m}, quantifiers and implicature \citep{GoodmanStuhlmuller2013:Knowledge-and-I,Tielvan-TielFranke2021:Probabilistic-p}, gradable adjectives \citep{LassiterGoodman2015:Adjectival-vagu}, or probability expression \citep{HerbstrittFranke2019:Complex-probabi}.
\mf{insert some more references (without MF as co-author!)}
Yet, some phenomena seem to require a more elaborate utility functions.
For example, in the realm of social meaning, extensions of the vanilla RSA model sketched above have been explored which incorporate additional utility components related to politeness \citep{YoonTessler2020:Polite-Speech-E}.
Here, we take a similar approach to modelling the utility trade-off between describing the world informatively and making an argument in favor of a position or hypothesis $H_{0}$, as opposed to the competing position or hypothesis $H_{1}$.
The general form of the extended speaker utility function we consider in this paper will be:
\begin{align}
  \label{eq:utilArgstrength}
  U(u , s , H_{0} , H_{1})
  &=
    \underbrace{{\mycolh{\beta}} \ \log P_{L_0} (s \mid \interpret{u})}_{\text{truth \& informativity}}
    \ + \
    \underbrace{(\mycolh{1-\beta}) \ \text{argstr}(u, H_{0} , H_{1})}_{\text{argumentative strength}}
    \ - \
    \underbrace{\text{cost}(u)}_{\text{economy}}\,.
\end{align}
Following the previous literature, the parameter $\beta$ models the degree to which a speaker values optimizing informativity of an utterance or making a strong argument for position $H_{0}$ (relative to $H_{1}$).
For the special case of $\beta = 1$, this formulation reduces to the previous utility function which did not have argumentative strength as an additional speaker objective for utterance selection.

In the following we will explore different models of the speaker's utterance choice:
\begin{enumerate}
  \item The \textbf{vanilla RSA model} provides the conservative baseline. It contains no speaker objective for argumentative speech; alternatively we can think of it as a model with $\beta=1$.
  \item The \textbf{likelihood-ratio model} assumes that argumentative strength can be operationalized in analogy to a common measure of observational evidence, the log-likelihood ratio (based on literal interpretation of the utterance).
  \item The \textbf{pragmatic likelihood-ratio model} is similar to the previous model but computes argumentative strength via log-likelihood ratios based on a pragmatic enrichment of the utterance.
  \item  The \textbf{maximin model} provides a computationally simpler definition of argumentative strength in terms of a form of worst-case reasoning.
  \item The \textbf{model-free model} uses a situation-specific notion of argumentative strength in terms of the posterior expectation of true answers; this approach is ``model-free'' in the sense that it does not commit to a strong theoretic position on what argument strength is supposed to be.
\end{enumerate}

\begin{draftytext}
  \begin{itemize}
    \item will explore a bunch of notions
    \item the starting point is log likelihood ratio
    \item used by a lot of previous work
    \item but no real quantitative model fits so far
  \end{itemize}
\end{draftytext}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiment}

To test whether and how speakers choose expressions to frame a complex situation with argumentative information culling, we used an experimental design which presents a perspicuous but complex state of affairs (the results of a high-school exam) and allows participants to choose flexibly from a larger, but still constrained set of alternative expressions.
The design used here is essentially the same as that of Experiment~1 reported in \citep{Vinicius-Macuch-SilvaWinter2024:Strategic-use-o}, except that we here used a larger set of visual scenes (different array sizes, see below).
While the work reported by \citet{Vinicius-Macuch-SilvaWinter2024:Strategic-use-o} also elicited and analyzed free production data, we here focus on a more constrained free-choice task in order to harness the complexity of the data for subsequent modeling in which participants could choose one of the 32 sentences of the scheme in (\ref{bsp:sentences-Exp}).

\begin{exe}
  \ex \label{bsp:sentences-Exp}
  Expression choice required selecting an outer and inner quantifier and an adjective:
  \begin{equation*}
  \label{eq:sentences}
  \left.
    \begin{matrix}
      \mathrm{None}\\
      \mathrm{Some}\\
      \mathrm{Most}\\
      \mathrm{All}
    \end{matrix}
  \right\}
  \text{ of the students got }
  \begin{Bmatrix}
    \mathrm{none}\\
    \mathrm{some}\\
    \mathrm{most}\\
    \mathrm{all}
  \end{Bmatrix}
  \text{ of the questions }
  \left\{
    \begin{matrix}
      \mathrm{right}\\
      \mathrm{wrong}
    \end{matrix}
  \right \}
  \,.
\end{equation*}

\end{exe}

\paragraph{Participants.}
A total of $N=201$ participants were recruited via Prolific (self-identified gender: 88 female, 111 male, 1 other and 1 non-disclosed; mean age (of those who revealed it) 30.3 (standard deviation 8.07), min 18 and max 60).
Participants had to be at least 18 years old in order to participate.
They were paid £1.5.
Based on a mean completion time of just below 10 minutes (median just below 9 minutes), this amounted to an average hourly payment of £1.5.
\mf{check: no other Prolific internal selection criteria; English etc.?}

\paragraph{Materials.}
The results of high-school exams were presented visually in form of matrices, as shown in Figure~\ref{fig:overview} (top left).
The rows of matrices corresponded to students (indicated by names), the columns indicated questions.
A checkmark on green background in a cell represented that the student got the question right.
A cross on a red background represented a false answer.
The results where always arranged to show students ordered in terms of performance (students with more correct answers on in higher rows).
The names of students were sampled at random for each trial from a list of common English first names.

Four sizes of matrices were used, differing in the number of students (5 or 11) and the number of questions in the exam (6 and 12).
For example, the matrix in Figure~\ref{fig:overview} is an instance of a $5 \times 12$ matrix.
For each matrix size, there were 20 instances, each one corresponding to one of the 20 situations which can be logically distinguished based on sentences of the form in (\ref{bsp:sentences-Exp}).
More concretely, the 20 situations are all the ``possible world states'' that can be differentiated with a language that contains only the sentences in (\ref{bsp:sentences-Exp}) under their standard logical meaning, assuming that \textit{some} means \textit{at least one} and \textit{most} means \textit{more than half} \citep[see][for details]{Vinicius-Macuch-SilvaWinter2024:Strategic-use-o}.

\paragraph{Procedure.}
The experiment started with an explanation of the displays and the task.
Participants were instructed to describe the results of high-school exams as either favorable or disfavorable (high vs.~low framing condition).
Each participant consistently saw one size of the four results matrices, and they saw each one of the 20 instances of that matrix type exactly once in completely randomized order.
Trials were randomly assigned to a high or low framing condition, so that each participant saw 10 trials in the high and 10 trials in the low framing condition.

\paragraph{Results.}
Following preregistered protocol, we excluded any response that is literally false as a description of the results shown in the corresponding trial.
This resulted in \mf{how many trials were excluded?}
We also excluded all the data from a participant if the participant selected the same response in all trials or if the participant gave more than 4 false responses.
This resulted in \mf{how many people were excluded?}
After cleaning, we had data from $N=\mf{fill me}$ participants.

\mf{TODO: implement exclusion criteria in R; get the numbers for this section; replot with proper data exclusion}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Models}
\label{sec:experiment}

We consider different model variants, each using a different notion of argumentative strength.

\subsection{Log likelihood ratio argstrength RSA}
\label{sec:argstrengthRSA}

The starting point is the notion of \emph{weight of evidence}, which has been introduced in the previous literature as a formal notion of argument strength, following \mf{refs}.
This notion requires fixing two competing hypotheses $H_{0}$ and $H_{1}$ and formalizes the argumentative strength of an utterance $u$ as evidence in favor of $H_{0}$ as opposed to the (alternative, competing) hypothesis $H_{1}$.
Concretely, we consider the degree to which the utterance $u$ is more likely to be true (literally) under hypothesis $H_{0}$ than under a competing (alternative) hypothesis $H_{1}$:
%
\begin{equation}
    \text{argstr}(u, H_{0}, H_{1}) = \log \frac{
    P( \interpret{u} \mid H_0 )
    }{
    P( \interpret{u} \mid H_1 )
    }
\end{equation}
%
\noindent where $P( \interpret{u} \mid H )$ is the probability that utterance $u$ is true given hypothesis $H$.

\bigskip

\begin{draftytext}
  To apply this definition to the case of our experiment, we have to specify what the competing hypotheses are, and how they condition the probability of $u$ being literally true.
  There are certainly degrees of freedom in this operationalization.
  The preregistered approach we report on here is as follows.
  Participants are instructed to argue that the students in a certain classroom have either a high probability of getting the questions right (\textit{high condition}) or a low probability of getting the questions right (\textit{low condition}).
  We make the simplifying assumption that the participants assume that all students in a class have the same probability $\gamma$ of answering each question correctly.
  Under this assumption, each observed exam result consists of $n_{s}$ samples (one per student) from a Binomial distribution with success parameter $\gamma$ and $n_{q}$ (i.e., the number of questions).
  Result for a participant therefore only conveys how many questions the participants answered correctly.
  On the other hand, students are identified individually with names in each trial.
  $H_0$ is then the hypothesis that the binomial probability parameter $p$ equals $\gamma$.
  Therefore:
  %
  \begin{align}
    P(\interpret{u} \mid \gamma)
    &= \sum_{s \in S}
      \left(
      s \in \interpret{u}
      K_s
      \right)
    \\
    K_s
    &\propto \prod_{k \in s}{ 12 \choose k } \gamma^k (1-\gamma)^{12-k}
  \end{align}
  %
  where $S$ is the set of exam arrays participants can observe in the experiment, each exam is encoded as a list of numbers of correct answers, and the binomial probabilities are normalized across the arrays in the experiment.

  Compared to the vanilla RSA model, this model has two additional parameters: $\beta$ and $\gamma$.
  These parameters are hard to infer jointly, but we have some prior knowledge that $\gamma$ is high in the high condition and low in the low condition.
  Therefore, we set $\gamma=0.85$ in the high condition and $\gamma=0.15$ in the low condition.

  We fit two versions of this model:
  \begin{enumerate}
    \item A version with completely pooled $\alpha$ and $\beta$.
    \item A version with by-participant $\alpha$, $\beta$.
  \end{enumerate}
\end{draftytext}

\subsection{Pragmatic argstrength RSA}

\begin{draftytext}
  The second model is the same as the log likelihood ratio argstrength RSA model described above, expect for the utility function which uses a different measure of argumentative strength: \mf{explain notation $w$ (world states)}
\end{draftytext}

\begin{align*}
\textrm{argstr}(u)
&= \log \frac{
P_{S} (u \mid H_0)
}{
P_{S} (u \mid H_1)
}
= \log \frac{
\sum_{w \in W} P_{S} (u \mid w) P(w \mid H_0)
}{
\sum_{w \in W} P_{S} (u \mid w) P(w \mid H_1)
}
\end{align*}

\noindent where $P_{S}$ is defined above in Equation~\eqref{eq:S1}.

\begin{draftytext}
  We fit two versions of this model:
  \begin{enumerate}
    \item A version with completely pooled $\alpha$ and $\beta$.
    \item A version with by-participant $\alpha$, $\beta$. This version assumes that each participant uses the same (estimated) value of $\alpha$ for the calculation of the argumentative strength and of the utility.
  \end{enumerate}
\end{draftytext}

\subsection{Maximin argstrength RSA}

\begin{draftytext}
  The third model we fit is meant to capture the intuition that, rather than minimizing full argumentative strength as defined above, participants might try to find the utterance $u$ such that the argumentatively weakest among the states compatible with $u$ is maximal. More formally, for each utterance $u$ participants might consider the following argumentative strength:

  \begin{align}
    \text{maximin-argstr}(u)
    &=
      \min_{s \in S} \log \frac{
      p( s \mid \interpret{u}, \gamma = 0.85)
      }{
      p( s \mid \interpret{u}, \gamma = 0.15 )
      } \\
    p( s \mid \interpret{u}, \gamma )
    &\propto\prod_{k \in s}{ 12 \choose k } \gamma^k (1-\gamma)^{12-k}
  \end{align}

  \noindent where $\gamma = 0.85$ encodes $H_0$ and $\gamma = 0.15$ encodes $H_1$. Other than the calculation of the argumentative strength, the model is identical to the model presented in Section \ref{sec:argstrengthRSA}.

  We fit two versions of this model:
  \begin{enumerate}
    \item A version with completely pooled $\alpha$ and $\beta$.
    \item A version with by-participant $\alpha$, $\beta$.
  \end{enumerate}
\end{draftytext}
\subsection{Model-free argstrength}

\begin{draftytext}
  In this version of the model, we define the measure of argumentative strength so that the arguing agent tries to maximize (in the high condition) or minimize (in the low condition) the expected total number of correct answers across all students given the utterance:\footnote{Here, $s$ is interpreted as a list of numbers, one for each student in the class, encoding the number of correct answers by the student.}

  \begin{align}
    \text{modelfree-argstr}(u)
    =&
       |\interpret{u}|^{-1} \sum_{s \in \interpret{u}} \sum_{i \in s} i
    & \text{High condition} \\
    \text{modelfree-argstr}(u)
    = - &
          |\interpret{u}|^{-1} \sum_{s \in \interpret{u}} \sum_{i \in s} i
    & \text{Low condition}
  \end{align}
  \noindent In words, the argumentative strength encodes the expected total number of right answers, which is to be (soft)maximised in the high condition and (soft)minimized in the low condition.

  This model has three free parameters to fit for each participant: $\alpha$, $\beta$, and the cost for `none'. Similarly to the previous models, we fit two versions of this model:
  \begin{enumerate}
    \item A completely pooled version
    \item A version with by-participant $\alpha$ and $\beta$ (and completely pooled `none' cost)
  \end{enumerate}
\end{draftytext}

\section{Results}

Figure~\ref{fig:results-model-comparison} shows the results of loo-based model comparison.
By expected log-likelihood under leave-one-out cross-validation, the best model is the hierarchical non-parametric model.
However, the second best model, the hierarchical maximin model, is not significantly worse under a simple $z$-test \mf{add reference Lambert}.

\begin{figure}[t]
  \centering
  \includegraphics[width = 0.9\textwidth]{pics/model_comparison-combined.pdf}
  \caption{
    Results of model comparison based on the full data set.
    For each model, shapes indicate the expected log-probability mass from leave-one-out cross validation, with error bars showing the standard error of these estimates.
    The $y$-axis lists the different types of models, ordered by ascending goodness-of-fit.
    The shapes and colors indicate the method of model fitting: with or without hierarchical structure.
  }
  \label{fig:results-model-comparison}
\end{figure}

\printbibliography[heading=bibintoc]

\end{document}
